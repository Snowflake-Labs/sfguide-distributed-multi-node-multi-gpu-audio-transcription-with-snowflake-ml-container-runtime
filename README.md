# Distributed Multi-Node and Multi GPU Audio Transcription with Snowflake ML Container Runtime

## Overview

In this guide, we will show how we can use ML Container runtime to perform multi-node, multi-gpu audio transcription over multiple audio files in a snowflake stage. In this demo, we use a GPU compute pool with 5 GPU_NV_S nodes and use `openai/whisper-large-v3` whisper model.

## Step-By-Step Guide

For prerequisites, environment setup, step-by-step guide and instructions, please refer to the [QuickStart Guide](https://quickstarts.snowflake.com/guide/getting_started_with_distributed_multi_node_multi_gpu_audio_transcription_with_snowflake_ml_container_runtime/index.html).
