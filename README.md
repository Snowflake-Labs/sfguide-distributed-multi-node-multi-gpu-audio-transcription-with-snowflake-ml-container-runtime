# Multi-Node, Multi-GPU Audio Transcription using Snowflake ML Container Runtime

## Overview

In this guide, we will show how we can use ML Container runtime to perform multi-node, multi-gpu audio transcription over multiple audio files in a snowflake stage. In this demo, we use a GPU compute pool with 5 GPU_NV_S nodes and use `openai/whisper-large-v3` whisper model.

## Step-By-Step Guide

For prerequisites, environment setup, step-by-step guide and instructions, please refer to the QuickStart Guide.
